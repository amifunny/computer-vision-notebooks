{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "faceNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YZYcBvxXq0u"
      },
      "source": [
        "\"\"\"\n",
        "  In this Notebook , we implement a \"FACENET\" MODEL widely used for face recogniton.\n",
        "\n",
        "  Paper - 'https://arxiv.org/abs/1503.03832'\n",
        "\n",
        "  Data - Bollywood Celeb Datset \n",
        "         and LFW - labeled faces in wild dataset\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPuMLoO31Ogb"
      },
      "source": [
        "api_token = {\"username\":\"<your_user_name_here>\",\"key\":\"<your_key_here>\"}\n",
        "\n",
        "import json\n",
        "\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJBvbSja0xkd"
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!touch ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3-xwTF3ZiG6"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import kaggle\n",
        "\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNteiDWorDEE"
      },
      "source": [
        "!kaggle datasets download -d havingfun/100-bollywood-celebrity-faces"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efBSVRfdn68Q"
      },
      "source": [
        "!unzip 100-bollywood-celebrity-faces.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpCUS8UCjf01"
      },
      "source": [
        "#  BOLLY WOOD SET\n",
        "import os\n",
        "import random\n",
        "\n",
        "batch_size = 8\n",
        "nob = 120\n",
        "total_trips = batch_size*nob\n",
        "\n",
        "def get_data():\n",
        "  Anchor = []\n",
        "  Positive = []\n",
        "  Negative = []\n",
        "\n",
        "  for i in range(total_trips):\n",
        "\n",
        "      try:\n",
        "        f_no = 'faces'+str(random.randrange(3))\n",
        "\n",
        "        noc = os.listdir('/content/'+f_no)\n",
        "        p_categ_no = random.randrange(len(noc))\n",
        "        n_categ_no = random.choice( list(range(0,p_categ_no)) + list(range(p_categ_no+1, len(noc))))\n",
        "\n",
        "        p_categ_path = '/content/'+f_no+'/'+noc[p_categ_no]\n",
        "        p_all_img = os.listdir(p_categ_path)\n",
        "        nop = len(p_all_img)\n",
        "\n",
        "        while(True):\n",
        "          a_no = random.randrange( nop )\n",
        "          p_no = random.choice( list(range(0,a_no)) + list(range(a_no+1, nop )) )\n",
        "          if (\".jpg\" in p_all_img[a_no] or \".jpeg\" in p_all_img[a_no]) and (\".jpg\" in p_all_img[p_no] or \".jpeg\" in p_all_img[p_no]):\n",
        "              # print(p_all_img[a_no])\n",
        "              break\n",
        "          else:\n",
        "              continue\n",
        "\n",
        "        n_categ_path = '/content/'+f_no+'/'+noc[n_categ_no]\n",
        "\n",
        "        n_all_img = os.listdir(n_categ_path)\n",
        "        while(True):\n",
        "          n_no = random.randrange( len(n_all_img) )\n",
        "          if (\".jpg\" in n_all_img[n_no] or \".jpeg\" in n_all_img[n_no]):\n",
        "              # print(n_all_img[n_no])\n",
        "              break\n",
        "          else:\n",
        "              continue\n",
        "\n",
        "        a_img = p_categ_path+'/'+p_all_img[a_no]\n",
        "        p_img = p_categ_path+'/'+p_all_img[p_no]\n",
        "        n_img = n_categ_path+'/'+n_all_img[n_no]\n",
        "\n",
        "        temp_arr = []\n",
        "        for each_img in [a_img,p_img,n_img]:\n",
        "            \n",
        "            image = Image.open(each_img)\n",
        "            image = image.resize((224,224))\n",
        "            arr = np.array(image)/255.0\n",
        "            arr = arr[:,:,:3]\n",
        "            temp_arr.append(arr)\n",
        "        \n",
        "        Anchor.append(temp_arr[0])\n",
        "        Positive.append(temp_arr[1])\n",
        "        Negative.append(temp_arr[2])\n",
        "      \n",
        "      except :\n",
        "        continue \n",
        "\n",
        "  return Anchor,Positive,Negative\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4mANiooBB-d"
      },
      "source": [
        "!wget 'http://vis-www.cs.umass.edu/lfw/lfw.tgz'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYDD186dBEJd"
      },
      "source": [
        "!tar -xvf 'lfw.tgz'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrMqvJOWBHQA"
      },
      "source": [
        "import os\n",
        "all_categs = os.listdir('/content/lfw')\n",
        "many_img_categ = []\n",
        "tota = 0\n",
        "peta = 0\n",
        "for each_categ in all_categs:\n",
        "\n",
        "    noi = len(os.listdir('/content/lfw/'+each_categ))\n",
        "    tota = tota+noi\n",
        "    if noi>1 and noi<=34:\n",
        "      peta = peta+noi\n",
        "      many_img_categ.append((each_categ,noi))\n",
        "\n",
        "print(tota)\n",
        "print(peta)\n",
        "print(many_img_categ)\n",
        "print(len(many_img_categ))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VnfNr7IBMYs"
      },
      "source": [
        "noc = len(many_img_categ)\n",
        "noft = 1000\n",
        "\n",
        "trip_categ = 0\n",
        "\n",
        "# this dataset can also be used\n",
        "# but in training loop we have only called \"get_data()\" ie bollywood dataset\n",
        "# LFW dataset\n",
        "def data_stroke():\n",
        "\n",
        "  Anchor = []\n",
        "  Positive = []\n",
        "  Negative = []\n",
        "\n",
        "  trip_num = 0\n",
        "  global trip_categ\n",
        "\n",
        "  while(trip_num<noft):\n",
        "\n",
        "    p_categ_no = trip_categ\n",
        "\n",
        "    p_categ = many_img_categ[p_categ_no][0]\n",
        "    noi_in_p = many_img_categ[p_categ_no][1]\n",
        "\n",
        "    no_each_trip = 0\n",
        "\n",
        "    for i in range(noi_in_p):\n",
        "\n",
        "      all_p_img = os.listdir('/content/lfw/'+p_categ)\n",
        "      a_img = all_p_img[ i ]                              \n",
        "      p_img = all_p_img[ (i+1)%noi_in_p ]\n",
        "\n",
        "      n_categ_no = random.choice( list(range(0,p_categ_no)) + list(range(p_categ_no+1, noc )))\n",
        "      n_categ = many_img_categ[n_categ_no][0]\n",
        "      all_n_img = os.listdir('/content/lfw/'+n_categ)\n",
        "      n_img_no = random.randrange(len(all_n_img))\n",
        "      \n",
        "      n_img = all_n_img[n_img_no]\n",
        "\n",
        "      no_each_trip = no_each_trip+1\n",
        "\n",
        "      a_img = '/content/lfw/'+p_categ+'/'+a_img\n",
        "      p_img = '/content/lfw/'+p_categ+'/'+p_img\n",
        "      n_img = '/content/lfw/'+n_categ+'/'+n_img\n",
        "\n",
        "      temp_arr = []\n",
        "      for each_img in [a_img,p_img,n_img]:\n",
        "          \n",
        "          image = Image.open(each_img)\n",
        "          image = image.resize((224,224))\n",
        "          arr = np.array(image)/255.0\n",
        "          arr = arr[:,:,:3]\n",
        "          temp_arr.append(arr)\n",
        "      \n",
        "      Anchor.append(temp_arr[0])\n",
        "      Positive.append(temp_arr[1])\n",
        "      Negative.append(temp_arr[2])\n",
        "\n",
        "    trip_num = trip_num + no_each_trip\n",
        "    trip_categ = trip_categ+1\n",
        "\n",
        "  return Anchor,Positive,Negative\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDaPKmgi0DRM"
      },
      "source": [
        "Anchor,Positive,Negative = data_stroke()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDcLhl8EJPsN"
      },
      "source": [
        "print(len(Anchor))\n",
        "print(len(Positive))\n",
        "print(len(Negative))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYiaZLpBsuh9"
      },
      "source": [
        "# View any triplet\n",
        "i=99\n",
        "for img in [Anchor[i],Positive[i],Negative[i]]:\n",
        "  show = plt.imshow(img)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSvqacP3vNuB"
      },
      "source": [
        "perm_index = np.random.permutation(len(Anchor))\n",
        "shuffle_A = []\n",
        "shuffle_P = []\n",
        "shuffle_N = []\n",
        "\n",
        "for i in perm_index:\n",
        "    shuffle_A.append(Anchor[i])\n",
        "    shuffle_P.append(Positive[i])\n",
        "    shuffle_N.append(Negative[i])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Mlf9OLYrUhx"
      },
      "source": [
        "i = 100\n",
        "\n",
        "show = plt.imshow(shuffle_A[i])\n",
        "plt.show()\n",
        "\n",
        "show = plt.imshow(shuffle_P[i])\n",
        "plt.show()\n",
        "\n",
        "show = plt.imshow(shuffle_N[i])\n",
        "plt.show()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-VSuBH36pz6"
      },
      "source": [
        "conv_constraint = tf.keras.constraints.MinMaxNorm(\n",
        "    min_value=-2.0, max_value=2.0, rate=1.0, axis=[0, 1, 2]\n",
        ")\n",
        "\n",
        "dense_constraint = tf.keras.constraints.MinMaxNorm(\n",
        "    min_value=-2.0, max_value=2.0, rate=1.0, axis=0\n",
        ")\n",
        "\n",
        "initial = tf.keras.initializers.he_normal(seed=15)\n",
        "\n",
        "inputs = tf.keras.layers.Input((224,224,3))\n",
        "\n",
        "out = tf.keras.layers.Conv2D(64,(3,3),padding='SAME',kernel_constraint=conv_constraint,activation='relu')(inputs)\n",
        "out = tf.keras.layers.Conv2D(64,(3,3),padding='SAME',kernel_constraint=conv_constraint,activation='relu')(out)\n",
        "out = tf.keras.layers.MaxPool2D((2,2))(out)\n",
        "out = tf.keras.layers.Conv2D(128,(3,3),padding='SAME',kernel_constraint=conv_constraint,activation='relu')(out)\n",
        "out = tf.keras.layers.Conv2D(128,(3,3),padding='SAME',kernel_constraint=conv_constraint,activation='relu')(out)\n",
        "out = tf.keras.layers.MaxPool2D((2,2))(out)\n",
        "out = tf.keras.layers.Conv2D(256,(3,3),padding='SAME',kernel_constraint=conv_constraint,activation='relu')(out)\n",
        "out = tf.keras.layers.Conv2D(256,(3,3),padding='SAME',kernel_constraint=conv_constraint,activation='relu')(out)\n",
        "out = tf.keras.layers.Conv2D(256,(3,3),padding='SAME',kernel_constraint=conv_constraint,activation='relu')(out)\n",
        "out = tf.keras.layers.MaxPool2D((2,2))(out)\n",
        "out = tf.keras.layers.Conv2D(512,(3,3),padding='SAME',kernel_constraint=conv_constraint,activation='relu')(out)\n",
        "out = tf.keras.layers.Conv2D(512,(3,3),padding='SAME',kernel_constraint=conv_constraint,activation='relu')(out)\n",
        "out = tf.keras.layers.Conv2D(512,(3,3),padding='SAME',kernel_constraint=conv_constraint,activation='relu')(out)\n",
        "out = tf.keras.layers.MaxPool2D((2,2))(out)\n",
        "out = tf.keras.layers.Conv2D(512,(3,3),padding='SAME',kernel_constraint=conv_constraint,activation='relu')(out)\n",
        "out = tf.keras.layers.Conv2D(512,(3,3),padding='SAME',kernel_constraint=conv_constraint,activation='relu')(out)\n",
        "out = tf.keras.layers.Conv2D(512,(3,3),padding='SAME',kernel_constraint=conv_constraint,activation='relu')(out)\n",
        "out = tf.keras.layers.MaxPool2D((2,2))(out)\n",
        "\n",
        "out = tf.keras.layers.Flatten()(out)\n",
        "out = tf.keras.layers.Dense(4096,activation='relu',kernel_constraint=dense_constraint)(out)\n",
        "out = tf.keras.layers.Dense(512,activation='relu',kernel_constraint=dense_constraint)(out)\n",
        "\n",
        "out = tf.keras.layers.Dense(128,kernel_constraint=dense_constraint)(out)\n",
        "outputs = tf.keras.layers.LayerNormalization()(out)\n",
        "\n",
        "model = 0\n",
        "model = tf.keras.Model(inputs=inputs,outputs=outputs)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jnqb8rChh4eH"
      },
      "source": [
        "alpha = 10\n",
        "def loss_func(A,P,N):\n",
        "\n",
        "    A_and_P = tf.reduce_sum( tf.square(A-P) , 1 )\n",
        "    A_and_N = tf.reduce_sum( tf.square(A-N) , 1 )\n",
        "\n",
        "    loss = A_and_P - A_and_N + alpha\n",
        "\n",
        "    final_loss = tf.math.maximum(loss,0.0)\n",
        "\n",
        "    final_loss = ( tf.reduce_sum(final_loss))+1e-10\n",
        "\n",
        "    return A_and_P,A_and_N,final_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzH5EAoBRYSt"
      },
      "source": [
        "tf.config.list_logical_devices('GPU')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rbh2s9z_gkyl"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(0.0001)\n",
        "mean = tf.keras.metrics.Mean()\n",
        "\n",
        "epochs = 2\n",
        "ctr = 0\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "  \n",
        "  for e in range(epochs):\n",
        "\n",
        "    trip_categ = 0\n",
        "\n",
        "    for stroke in range(4):\n",
        "\n",
        "      # after every two loop change data\n",
        "      if(stroke%2==0):\n",
        "        Anchor,Positive,Negative = get_data()\n",
        "        batch_size = 8\n",
        "        num_of_batches = int(len(Anchor)/batch_size)-1\n",
        "      print(\"STROKE {} ===> batches :: {}\".format(stroke,num_of_batches))\n",
        "\n",
        "      mean.reset_states()\n",
        "      for b in range(num_of_batches):\n",
        "\n",
        "        batch_A = np.array( Anchor[(b)*batch_size:(b+1)*batch_size] )\n",
        "        batch_P = np.array( Positive[(b)*batch_size:(b+1)*batch_size] )\n",
        "        batch_N = np.array( Negative[(b)*batch_size:(b+1)*batch_size] )\n",
        "\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "\n",
        "            A_vec = model(batch_A)\n",
        "            P_vec = model(batch_P)\n",
        "            N_vec = model(batch_N)\n",
        "\n",
        "            A_and_P,A_and_N,loss = loss_func(A_vec,P_vec,N_vec)\n",
        "            mean.update_state(loss)\n",
        "\n",
        "\n",
        "        grads = tape.gradient( loss , model.trainable_variables )\n",
        "        optimizer.apply_gradients( zip(grads,model.trainable_variables) )\n",
        "\n",
        "\n",
        "        if ctr%20==0: \n",
        "          print(\"loss  ::======  ==>   {}\".format(mean.result()))  \n",
        "\n",
        "        ctr = ctr+1\n",
        "      \n",
        "      print(\"Epoch {} ::  ==>   {}\".format(e,mean.result()))  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSKUdKgAQLpC"
      },
      "source": [
        "model.save('face_id.h5')\n",
        "#  OR this\n",
        "# model.save('saved_model/my_model')\n",
        "\n",
        "# to download this model\n",
        "# from google.colab import files\n",
        "# files.download('face_id.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ-e1bEmwng8"
      },
      "source": [
        "# TESTING ON MATT DAMON VS MARK WALBERG ; )\n",
        "!wget -O 'A.jpg' 'https://thumbor.forbes.com/thumbor/fit-in/416x416/filters%3Aformat%28jpg%29/https%3A%2F%2Fspecials-images.forbesimg.com%2Fimageserve%2F577fe96da7ea436bd18c3ef7%2F0x0.jpg%3Fbackground%3D000000%26cropX1%3D0%26cropX2%3D744%26cropY1%3D15%26cropY2%3D759'\n",
        "!wget -O 'P.jpg' 'https://upload.wikimedia.org/wikipedia/commons/8/83/Matt_Damon_TIFF_2015.jpg'\n",
        "!wget -O 'N.jpg' 'https://www.gstatic.com/tv/thumb/persons/43431/43431_v9_ba.jpg'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39Jsbt3NxSCD"
      },
      "source": [
        "files = ['A.jpg','P.jpg','N.jpg']\n",
        "use_img = []\n",
        "for img_path in files:\n",
        "\n",
        "    each_img = Image.open(img_path)\n",
        "\n",
        "    each_img = np.array(each_img.resize((224,224)))/255.0\n",
        "\n",
        "    img = each_img.astype(np.float32)\n",
        "\n",
        "    show = plt.imshow( img )\n",
        "    plt.show()\n",
        "    use_img.append(img)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62j2JCC-4G45"
      },
      "source": [
        "def get_diff(vec1,vec2):\n",
        "\n",
        "    diff = tf.reduce_sum(tf.square(vec1-vec2))\n",
        "    return diff.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkTXQ7WbpWr8"
      },
      "source": [
        "vec_A = model( tf.expand_dims(use_img[0],0) )\n",
        "vec_P = model( tf.expand_dims(use_img[1],0) )\n",
        "vec_N = model( tf.expand_dims(use_img[2],0) )\n",
        "\n",
        "A_and_P = get_diff(vec_A,vec_P)\n",
        "A_and_N = get_diff(vec_A,vec_N)\n",
        "\n",
        "print(\"difference b/w A and P ==> {}\".format(A_and_P))\n",
        "print(\"difference b/w A and N ==> {}\".format(A_and_N))\n",
        "\n",
        "\"\"\"\n",
        "  Difference B/W A & P should be less than A & N , that what we trained the Network for.\n",
        "  To tell the degree of difference b/w faces.\n",
        "\n",
        "  Feel Free to Try other Confusing Images from Net.\n",
        "  \n",
        "  Congrats ! You have trained a very good Face Recognition Model. \n",
        "  You can use it for Practical purposes.\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}